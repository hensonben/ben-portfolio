<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>YouTube Comment Classifier | Benjamin Henson</title>
<meta name="keywords" content="">
<meta name="description" content="A DistilBERT model that classifies YouTube comments by sentiment">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/projects/yt-classifier/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/projects/yt-classifier/index.xml" title="rss">
<link rel="alternate" hreflang="en" href="http://localhost:1313/projects/yt-classifier/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }
    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/custom.css" />
<header class="navbar">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/about/">About</a></li>
    <li><a href="/projects/">Projects</a></li>
    <li><a href="/contact/">Contact</a></li>
  </ul>
</header>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-mLLfwC3roQoPCaC9HIcA3zD8uR+ymcU+nMMT+X2SVI33NnEw5e99bGyADf8p+8db" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-z3bOTo6a5x1EdtSxRwLKtB3bWucCJQ2eN7qvJkMTvhvE8DaRUT8yqRpxW6fUR0Hk" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-mllN6pFyz9ZxdpKxZBvTTQ9bRkOa5GqJycGP4sdFZbQvRkLMRnKx2y8c5jDqJemr" crossorigin="anonymous"
    onload="renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true},
        {left: '\\[', right: '\\]', display: true},
        {left: '$', right: '$', display: false},
        {left: '\\(', right: '\\)', display: false}
      ],
      throwOnError: false
    });">
</script>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    tags: 'ams'
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  svg: { fontCache: 'global' }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
</head>

<body class="list dark" id="top">


    
    <main class="main"> 
<header class="page-header">
  <h1>
    YouTube Comment Classifier
  </h1>
  <div class="post-description">
    A DistilBERT model that classifies YouTube comments by sentiment
  </div>
</header>
<div class="post-content"><h2 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h2>
<p>This project fine-tunes a <strong>DistilBERT Transformer</strong>model to classify YouTube comments into positive, neutral, or negative sentiments.
The goal was to gain hands-on experience with <strong>Natural Language Processing (NLP)</strong> and explore the process of fine-tuning pretrained language models using <strong>Hugging Face Transformers</strong> and <strong>PyTorch</strong>.</p>
<p>The dataset was sourced from Kaggle and consists of real YouTube user comments labeled by sentiment. <em>See end of page for a link to the dataset if so inclined.</em></p>
<h3 id="tools-and-libraries">Tools and Libraries<a hidden class="anchor" aria-hidden="true" href="#tools-and-libraries">#</a></h3>
<ul>
<li>Python 3.13</li>
<li>Hugging Face Transformers (v4.57.1)</li>
<li>Datasets (Hugging Face)</li>
<li>PyTorch 2.8.0</li>
<li>Accelerate 1.10.1</li>
</ul>
<h3 id="model-and-training-details">Model and Training Details<a hidden class="anchor" aria-hidden="true" href="#model-and-training-details">#</a></h3>
<p>After preprocessing, the text was <strong>tokenized</strong> and converted into numerical input for the model. Additionally, sentiment labels were encoded as integers (0 = negative, 1 = neutral, 2 = positive)</p>
<h3 id="model-distilbert-base-uncased">Model: <code>distilbert-base-uncased</code><a hidden class="anchor" aria-hidden="true" href="#model-distilbert-base-uncased">#</a></h3>
<p>This is a lightweight version of <strong>BERT</strong> (Bidirectional Encoder Representations from Transformers) that retains most of BERT&rsquo;s accuracy while being both faster and smaller. Additionally, it&rsquo;s pretrained on large text data and fine-tuned here for sentiment classification. This project allowed the model to learn, rather than strictly memorize, the nuance and emotion (think sarcasm, humor, etc.) behind words in a given sentence.<br>
<a href="/projects/yt-classifier/_bert-info/">More on BERT</a></p>
<h3 id="task-sequence-classification">Task: <em>Sequence Classification</em><a hidden class="anchor" aria-hidden="true" href="#task-sequence-classification">#</a></h3>
<p>The model learns to assign one of three sentiment categories (positive, neutral, or negative) to each input text sequence (YouTube comment).</p>
<h3 id="traintest-split-8020">Train/Test Split: <em>80/20</em><a hidden class="anchor" aria-hidden="true" href="#traintest-split-8020">#</a></h3>
<p>80% of the dataset is used for training the model, while 20% is reserved for evaluating how well it generalizes to unseen data.</p>
<h3 id="batch-size-8">Batch Size: <em>8</em><a hidden class="anchor" aria-hidden="true" href="#batch-size-8">#</a></h3>
<p>During training, the model processes 8 examples at a time before updating its weights. Smaller batch sizes can help with limited GPU memory and improve generalization slightly.</p>
<h3 id="learning-rate-2e-5">Learning Rate: <code>2e-5</code><a hidden class="anchor" aria-hidden="true" href="#learning-rate-2e-5">#</a></h3>
<p>Controls how much the model’s weights are adjusted during training.<br>
A smaller learning rate helps prevent the model from “overshooting” the optimal solution.</p>
<h3 id="epochs-2">Epochs: <em>2</em><a hidden class="anchor" aria-hidden="true" href="#epochs-2">#</a></h3>
<p>An <em>epoch</em> represents one complete pass through the entire training dataset.<br>
After two passes, the model’s performance had plateaued, indicating that additional training would not meaningfully improve results.</p>
<h3 id="weight-decay-001">Weight Decay: <em>0.01</em><a hidden class="anchor" aria-hidden="true" href="#weight-decay-001">#</a></h3>
<p>A regularization technique that prevents overfitting by slightly penalizing large weights during optimization. This encourages the model to maintain simpler, more generalizable parameter values.</p>
<h3 id="optimizer-adamw">Optimizer: <em>AdamW</em><a hidden class="anchor" aria-hidden="true" href="#optimizer-adamw">#</a></h3>
<p>A variant of the Adam optimizer that integrates weight decay directly into the update rule.<br>
It is widely used for fine-tuning Transformer-based models such as BERT and DistilBERT, providing stable convergence and reduced overfitting.<br>
<a href="/projects/yt-classifier/_adam-info/">More on Adam</a></p>
<h3 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th style="text-align: center">Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Training Loss</strong></td>
          <td style="text-align: center">0.37</td>
      </tr>
      <tr>
          <td><strong>Evaluation Loss</strong></td>
          <td style="text-align: center">0.49</td>
      </tr>
      <tr>
          <td><strong>Accuracy</strong></td>
          <td style="text-align: center">0.84</td>
      </tr>
      <tr>
          <td><strong>Weighted F1 Score</strong></td>
          <td style="text-align: center">0.84</td>
      </tr>
  </tbody>
</table>
<p>These metrics evaluate how well the fine-tuned model performs in classifying the sentiment of YouTube comments.</p>
<ul>
<li>
<h3 id="training-loss--037"><strong>Training Loss — 0.37</strong><a hidden class="anchor" aria-hidden="true" href="#training-loss--037">#</a></h3>
<p>Represents how far the model’s predictions are from the correct labels during training.<br>
A low training loss indicates that the model successfully learned from the dataset without overfitting.</p>
</li>
<li>
<h3 id="evaluation-loss--049"><strong>Evaluation Loss — 0.49</strong><a hidden class="anchor" aria-hidden="true" href="#evaluation-loss--049">#</a></h3>
<p>Calculated on a separate validation set that the model did not see during training.<br>
The slightly higher loss compared to training is expected and shows that the model generalizes reasonably well to unseen data.</p>
</li>
<li>
<h3 id="accuracy--084"><strong>Accuracy — 0.84</strong><a hidden class="anchor" aria-hidden="true" href="#accuracy--084">#</a></h3>
<p>Indicates that the model correctly classifies about <strong>84%</strong> of comments into the appropriate sentiment categories (positive, negative, or neutral).<br>
Accuracy provides a straightforward measure of overall correctness.</p>
</li>
<li>
<h3 id="weighted-f1-score--084"><strong>Weighted F1 Score — 0.84</strong><a hidden class="anchor" aria-hidden="true" href="#weighted-f1-score--084">#</a></h3>
<p>Balances <strong>precision</strong> (how many predicted sentiments were correct) and <strong>recall</strong> (how many actual sentiments were detected).<br>
The <em>weighted</em> version accounts for differences in class sizes, ensuring that all sentiment categories are evaluated fairly.<br>
A score of <strong>0.84</strong> demonstrates that the model performs consistently across different comment types.</p>
</li>
</ul>
<hr>
<p>Overall the model achieved strong performance on unseen YouTube comments, which demonstrated effective transfer learning from pretrained weights to real-world text.</p>
<h3 id="model-access">Model Access<a hidden class="anchor" aria-hidden="true" href="#model-access">#</a></h3>
<p>You can test and download the fine-tuned model directly on Hugging Face:<br>
<a href="https://huggingface.co/azande7/yt-sentiment-model">https://huggingface.co/azande7/yt-sentiment-model</a></p>
<p>Link to the dataset: (<a href="https://www.kaggle.com/datasets/atifaliak/youtube-comments-dataset">https://www.kaggle.com/datasets/atifaliak/youtube-comments-dataset</a>)</p>
<hr>
<h2 id="try-it-yourself">Try It Yourself<a hidden class="anchor" aria-hidden="true" href="#try-it-yourself">#</a></h2>
<p>Enter a YouTube comment below to see how the model classifies it.</p>
<div class="classifier-demo">
  <textarea id="userInput" rows="3" placeholder="Type a YouTube comment..." style="width:100%;padding:10px;border-radius:8px;border:none;margin-top:10px;"></textarea>
  <br>
  <button onclick="classifyComment()" style="margin-top:10px;padding:8px 14px;border:none;border-radius:8px;background:#a78bfa;color:white;font-weight:bold;cursor:pointer;">
    Classify
  </button>
  <p id="result" style="margin-top:1rem;font-weight:bold;"></p>
</div>
<script>
async function classifyComment() {
  const input = document.getElementById('userInput').value;
  const resultElement = document.getElementById('result');

  resultElement.textContent = 'Analyzing...';

  const response = await fetch("https://api-inference.huggingface.co/models/azande7/yt-sentiment-model", {
    headers: { "Authorization": "Bearer $HUGGINGFACE_TOKEN" },
    method: "POST",
    body: JSON.stringify({ inputs: input }),
  });

  const data = await response.json();
  resultElement.textContent = `Prediction: ${data[0][0].label} (Confidence: ${(data[0][0].score * 100).toFixed(2)}%)`;
}
</script>


</div>
    </main>

    
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Benjamin Henson</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body, {delimiters:[{left:'$$', right:'$$', display:true}, {left:'$', right:'$', display:false}, {left:'\\\\(', right:'\\\\)', display:false}, {left:'\\\\[', right:'\\\\]', display:true}]});"></script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>
</html>