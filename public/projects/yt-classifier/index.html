<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>YouTube Comment Classifier | Benjamin Henson</title>
<meta name="keywords" content="">
<meta name="description" content="
🧠 Try It Yourself

Example Prompts: (Encouraged to try your own!)
Clear Sentiment | Average Confidence: 95%
These are simple and direct.

&ldquo;This video was amazing! Learned so much ❤️”
“Bro this deserves way more views.”
“The editing and pacing were perfect!”
“This was a complete waste of time.”
“Why did I even click on this?”
“Terrible audio, couldn’t even finish watching.”
&ldquo;This video is 10 minutes long.”
“Uploaded on October 16th.”
“I came here after seeing the thumbnail.”

Emotional Tone or Slightly Ambiguous | Average Confidence: 80%
These require the model to pay attention to emotion and context.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/projects/yt-classifier/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a090830a421002426baafbd314e38f149d77b4c48a12ee9312700d770b27fb26.css" integrity="sha256-oJCDCkIQAkJrqvvTFOOPFJ13tMSKEu6TEnANdwsn&#43;yY=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/projects/yt-classifier/index.xml" title="rss">
<link rel="alternate" hreflang="en" href="http://localhost:1313/projects/yt-classifier/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }
    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
    <link rel="stylesheet" href="/css/custom.css" />
<header class="navbar">
  <ul>
    <li><a href="/">Home</a></li>
    <li><a href="/about/">About</a></li>
    <li><a href="/projects/">Projects</a></li>
    <li><a href="/contact/">Contact</a></li>
  </ul>
</header>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-mLLfwC3roQoPCaC9HIcA3zD8uR+ymcU+nMMT+X2SVI33NnEw5e99bGyADf8p+8db" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-z3bOTo6a5x1EdtSxRwLKtB3bWucCJQ2eN7qvJkMTvhvE8DaRUT8yqRpxW6fUR0Hk" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-mllN6pFyz9ZxdpKxZBvTTQ9bRkOa5GqJycGP4sdFZbQvRkLMRnKx2y8c5jDqJemr" crossorigin="anonymous"
    onload="renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true},
        {left: '\\[', right: '\\]', display: true},
        {left: '$', right: '$', display: false},
        {left: '\\(', right: '\\)', display: false}
      ],
      throwOnError: false
    });">
</script>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    tags: 'ams'
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  svg: { fontCache: 'global' }
};
</script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
</head>

<body class="list dark" id="top">


    
    <main class="main"> 
<header class="page-header">
  <h1>
    YouTube Comment Classifier
  </h1>
</header>
<div class="post-content"><hr>
<h2 id="-try-it-yourself">🧠 Try It Yourself<a hidden class="anchor" aria-hidden="true" href="#-try-it-yourself">#</a></h2>
<iframe
	src="https://azande7-yt-sentiment-demo.hf.space"
	frameborder="0"
	width="850"
	height="450"
  scrolling="no"
></iframe>
<h2 id="example-prompts-encouraged-to-try-your-own">Example Prompts: (Encouraged to try your own!)<a hidden class="anchor" aria-hidden="true" href="#example-prompts-encouraged-to-try-your-own">#</a></h2>
<h3 id="clear-sentiment--average-confidence-95">Clear Sentiment | Average Confidence: 95%<a hidden class="anchor" aria-hidden="true" href="#clear-sentiment--average-confidence-95">#</a></h3>
<p>These are simple and direct.</p>
<ul>
<li>&ldquo;This video was amazing! Learned so much ❤️”</li>
<li>“Bro this deserves way more views.”</li>
<li>“The editing and pacing were perfect!”</li>
<li>“This was a complete waste of time.”</li>
<li>“Why did I even click on this?”</li>
<li>“Terrible audio, couldn’t even finish watching.”</li>
<li>&ldquo;This video is 10 minutes long.”</li>
<li>“Uploaded on October 16th.”</li>
<li>“I came here after seeing the thumbnail.”</li>
</ul>
<h3 id="emotional-tone-or-slightly-ambiguous--average-confidence-80">Emotional Tone or Slightly Ambiguous | Average Confidence: 80%<a hidden class="anchor" aria-hidden="true" href="#emotional-tone-or-slightly-ambiguous--average-confidence-80">#</a></h3>
<p>These require the model to pay attention to emotion and context.</p>
<ul>
<li>“Didn’t expect to like it, but this was actually really good.”</li>
<li>“You can tell they put real effort into this.”</li>
<li>“I mean… it’s fine, but definitely not great.”</li>
<li>“Could have been better. Not what I hoped for.”</li>
<li>“I’m not sure how to feel about this.”</li>
<li>“The topic is interesting but poorly explained.”</li>
</ul>
<h3 id="sarcasm-mixed-emotions-or-subtle-negativity--average-confidence-82">Sarcasm, Mixed Emotions, or Subtle Negativity | Average Confidence: 82%<a hidden class="anchor" aria-hidden="true" href="#sarcasm-mixed-emotions-or-subtle-negativity--average-confidence-82">#</a></h3>
<p>These test how well the model understands nuance.</p>
<ul>
<li>“Oh wow, another completely original reaction video 🙄.”</li>
<li>“Just what the internet needed… more unboxing videos.”</li>
<li>“Good visuals, but the message didn’t land.”</li>
<li>“Loved the first half, but it totally fell apart at the end.”</li>
<li>“Not really my thing, but I can see why people like it.”</li>
<li>“Nice effort, though the execution could use some work.”</li>
</ul>
<h2 id="overview">Overview<a hidden class="anchor" aria-hidden="true" href="#overview">#</a></h2>
<p>This project fine-tunes a <strong>DistilBERT Transformer</strong>model to classify YouTube comments into positive, neutral, or negative sentiments.
The goal was to gain hands-on experience with <strong>Natural Language Processing (NLP)</strong> and explore the process of fine-tuning pretrained language models using <strong>Hugging Face Transformers</strong> and <strong>PyTorch</strong>.</p>
<p>The dataset was sourced from Kaggle and consists of real YouTube user comments labeled by sentiment. <em>See end of page for a link to the dataset if so inclined.</em></p>
<h3 id="tools-and-libraries">Tools and Libraries<a hidden class="anchor" aria-hidden="true" href="#tools-and-libraries">#</a></h3>
<ul>
<li>Python 3.13</li>
<li>Hugging Face Transformers (v4.57.1)</li>
<li>Datasets (Hugging Face)</li>
<li>PyTorch 2.8.0</li>
<li>Accelerate 1.10.1</li>
</ul>
<h3 id="model-and-training-details">Model and Training Details<a hidden class="anchor" aria-hidden="true" href="#model-and-training-details">#</a></h3>
<p>After preprocessing, the text was <strong>tokenized</strong> and converted into numerical input for the model. Additionally, sentiment labels were encoded as integers (0 = negative, 1 = neutral, 2 = positive)</p>
<h3 id="model-distilbert-base-uncased">Model: <code>distilbert-base-uncased</code><a hidden class="anchor" aria-hidden="true" href="#model-distilbert-base-uncased">#</a></h3>
<p>This is a lightweight version of <strong>BERT</strong> (Bidirectional Encoder Representations from Transformers) that retains most of BERT&rsquo;s accuracy while being both faster and smaller. Additionally, it&rsquo;s pretrained on large text data and fine-tuned here for sentiment classification. This project allowed the model to learn, rather than strictly memorize, the nuance and emotion (think sarcasm, humor, etc.) behind words in a given sentence.<br>
<a href="/projects/yt-classifier/_bert-info/">More on BERT</a></p>
<h3 id="task-sequence-classification">Task: <em>Sequence Classification</em><a hidden class="anchor" aria-hidden="true" href="#task-sequence-classification">#</a></h3>
<p>The model learns to assign one of three sentiment categories (positive, neutral, or negative) to each input text sequence (YouTube comment).</p>
<h3 id="traintest-split-8020">Train/Test Split: <em>80/20</em><a hidden class="anchor" aria-hidden="true" href="#traintest-split-8020">#</a></h3>
<p>80% of the dataset is used for training the model, while 20% is reserved for evaluating how well it generalizes to unseen data.</p>
<h3 id="batch-size-8">Batch Size: <em>8</em><a hidden class="anchor" aria-hidden="true" href="#batch-size-8">#</a></h3>
<p>During training, the model processes 8 examples at a time before updating its weights. Smaller batch sizes can help with limited GPU memory and improve generalization slightly.</p>
<h3 id="learning-rate-2e-5">Learning Rate: <code>2e-5</code><a hidden class="anchor" aria-hidden="true" href="#learning-rate-2e-5">#</a></h3>
<p>Controls how much the model’s weights are adjusted during training.<br>
A smaller learning rate helps prevent the model from “overshooting” the optimal solution.</p>
<h3 id="epochs-2">Epochs: <em>2</em><a hidden class="anchor" aria-hidden="true" href="#epochs-2">#</a></h3>
<p>An <em>epoch</em> represents one complete pass through the entire training dataset.<br>
After two passes, the model’s performance had plateaued, indicating that additional training would not meaningfully improve results.</p>
<h3 id="weight-decay-001">Weight Decay: <em>0.01</em><a hidden class="anchor" aria-hidden="true" href="#weight-decay-001">#</a></h3>
<p>A regularization technique that prevents overfitting by slightly penalizing large weights during optimization. This encourages the model to maintain simpler, more generalizable parameter values.</p>
<h3 id="optimizer-adamw">Optimizer: <em>AdamW</em><a hidden class="anchor" aria-hidden="true" href="#optimizer-adamw">#</a></h3>
<p>A variant of the Adam optimizer that integrates weight decay directly into the update rule.<br>
It is widely used for fine-tuning Transformer-based models such as BERT and DistilBERT, providing stable convergence and reduced overfitting.<br>
<a href="/projects/yt-classifier/_adam-info/">More on Adam</a></p>
<h3 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h3>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th style="text-align: center">Score</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Training Loss</strong></td>
          <td style="text-align: center">0.37</td>
      </tr>
      <tr>
          <td><strong>Evaluation Loss</strong></td>
          <td style="text-align: center">0.49</td>
      </tr>
      <tr>
          <td><strong>Accuracy</strong></td>
          <td style="text-align: center">0.84</td>
      </tr>
      <tr>
          <td><strong>Weighted F1 Score</strong></td>
          <td style="text-align: center">0.84</td>
      </tr>
  </tbody>
</table>
<p>These metrics evaluate how well the fine-tuned model performs in classifying the sentiment of YouTube comments.</p>
<ul>
<li>
<h3 id="training-loss--037"><strong>Training Loss — 0.37</strong><a hidden class="anchor" aria-hidden="true" href="#training-loss--037">#</a></h3>
<p>Represents how far the model’s predictions are from the correct labels during training.<br>
A low training loss indicates that the model successfully learned from the dataset without overfitting.</p>
</li>
<li>
<h3 id="evaluation-loss--049"><strong>Evaluation Loss — 0.49</strong><a hidden class="anchor" aria-hidden="true" href="#evaluation-loss--049">#</a></h3>
<p>Calculated on a separate validation set that the model did not see during training.<br>
The slightly higher loss compared to training is expected and shows that the model generalizes reasonably well to unseen data.</p>
</li>
<li>
<h3 id="accuracy--084"><strong>Accuracy — 0.84</strong><a hidden class="anchor" aria-hidden="true" href="#accuracy--084">#</a></h3>
<p>Indicates that the model correctly classifies about <strong>84%</strong> of comments into the appropriate sentiment categories (positive, negative, or neutral).<br>
Accuracy provides a straightforward measure of overall correctness.</p>
</li>
<li>
<h3 id="weighted-f1-score--084"><strong>Weighted F1 Score — 0.84</strong><a hidden class="anchor" aria-hidden="true" href="#weighted-f1-score--084">#</a></h3>
<p>Balances <strong>precision</strong> (how many predicted sentiments were correct) and <strong>recall</strong> (how many actual sentiments were detected).<br>
The <em>weighted</em> version accounts for differences in class sizes, ensuring that all sentiment categories are evaluated fairly.<br>
A score of <strong>0.84</strong> demonstrates that the model performs consistently across different comment types.</p>
</li>
</ul>
<hr>
<p>Overall the model achieved strong performance on unseen YouTube comments, which demonstrated effective transfer learning from pretrained weights to real-world text.</p>
<h3 id="model-access">Model Access<a hidden class="anchor" aria-hidden="true" href="#model-access">#</a></h3>
<p>You can test and download the fine-tuned model directly on Hugging Face:<br>
<a href="https://huggingface.co/azande7/yt-sentiment-model">https://huggingface.co/azande7/yt-sentiment-model</a></p>
<p>Link to the dataset: (<a href="https://www.kaggle.com/datasets/atifaliak/youtube-comments-dataset">https://www.kaggle.com/datasets/atifaliak/youtube-comments-dataset</a>)</p>
<hr>


</div>
    </main>

    
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Benjamin Henson</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body, {delimiters:[{left:'$$', right:'$$', display:true}, {left:'$', right:'$', display:false}, {left:'\\\\(', right:'\\\\)', display:false}, {left:'\\\\[', right:'\\\\]', display:true}]});"></script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>
</html>